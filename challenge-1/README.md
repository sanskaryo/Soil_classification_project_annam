# ğŸŒ± Soil Image Classification â€“ Challenge 1

Welcome to my solution for Challenge 1 of the Soil Classification Competition on Kaggle 2025. In this notebook-driven project, our goal was to classify soil images into four distinct categories based on visual characteristics:

- **Alluvial**  
- **Black**  
- **Clay**  
- **Red**  

We combine a deepâ€learning feature extractor (ResNet-18) with a classical Random Forest classifier to build a robust multiâ€class image classifier.

---

## ğŸš€ Final Results

| Metric                              | Value   |
|-------------------------------------|--------:|
| ğŸ Private Leaderboard Rank          | 40      |
| â€¢ Avg CV Macro F1-Score              | 0.9446  |
| â€¢ Best Fold (Fold 5) F1-Score        | 0.9705  |
| â€¢ Public LB Score                    | 1.000   |

ğŸ† **Submission Strategy:** ResNet18 (ImageNet-pretrained) + Random Forest Ensemble learning

---

## ğŸ” Problem Statement

Build a robust classifier that can distinguish between soil types using only RGB images. Key challenges:

- Visual similarity & texture variations  
- Lighting and background noise  
- Class imbalance  

---

## ğŸ—ºï¸ Pipeline Overview
Below is a vertical diagram illustrating the main structure of the classification pipeline:

![Pipeline Diagram](docs/cards/challenege1_image.png)

## ğŸ“¦ Dataset

Download from Kaggle:  
https://www.kaggle.com/competitions/soil-classification/data

Unpack into your project directory as:

```
challenge-1/
â””â”€â”€ data/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ image_1.jpg
    â”‚   â”œâ”€â”€ image_2.jpg
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ test/
    â”‚   â”œâ”€â”€ image_101.jpg
    â”‚   â”œâ”€â”€ image_102.jpg
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ train_labels.csv
    â””â”€â”€ test_ids.csv
```

---

## ğŸ› ï¸ Setup

1. **Clone the repository**
   ```cmd
   git clone https://github.com/sanskaryo/Soil_classification_project_annam.git
   cd Soil_classification_project_annam/challenge-1
   ```

2. **Install dependencies**
   ```cmd
   pip install -r requirements.txt
   ```

---

## ğŸ”„ Preprocess Data

Use the provided helper to resize and normalize all images:

```python
from src.preprocessing import preprocess_images

# Resize train and test images to 224Ã—224
preprocess_images(
    train_dir='data/train',
    img_size=(224, 224),
    out_dir='data/train_preprocessed'
)
preprocess_images(
    train_dir='data/test',
    img_size=(224, 224),
    out_dir='data/test_preprocessed'
)
```

---

## ğŸ“– Training

1. Open and run:  
   ```markdown
   notebooks/training.ipynb
   ```
2. This notebook will:
   - Load and augment images  
   - Extract features via ResNet-18  
   - Train & validate a Random Forest (5-fold CV)  
   - Save `models/final_model.pkl` and `models/label_classes.npy`

---

## ğŸ”® Inference

1. Open and run:  
   ```markdown
   notebooks/inference.ipynb
   ```
2. It will:
   - Reload the saved model & label classes  
   - Extract features on the test set  
   - Generate `outputs/submission.csv`

---

## ğŸš€ One-Click Run

To run preprocessing, training & inference in one go (with charts), open and execute:
```
src/combined-prePost-notebook_with_charts.ipynb
```
A final `submission.csv` will be generated under `outputs/`.

---

## ğŸ“ Project Structure

```
challenge-1/
â”œâ”€â”€ data/                          # Raw and preprocessed images + CSVs
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ training.ipynb            # End-to-end training pipeline
â”‚   â”œâ”€â”€ inference.ipynb           # Inference & submission generation
â”‚   â””â”€â”€ combined-prePost-notebook_with_charts.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py          # Image transforms & feature extraction
â”‚   â”œâ”€â”€ postprocessing.py         # Submission utilities
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ final_model.pkl           # Trained Random Forest model
â”‚   â””â”€â”€ label_classes.npy         # Label encoder classes
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ submission.csv            # Final submission file
â”‚   â””â”€â”€ metrics.json              # CV and evaluation logs
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
```

---

## --- Fold 5 ---
Fold 5 F1 Score: 0.9705

```text
               precision    recall  f1-score   support

Alluvial soil       0.97      0.97      0.97       105
   Black Soil       1.00      0.93      0.97        46
    Clay soil       0.95      0.97      0.96        40
     Red soil       0.96      1.00      0.98        53

     accuracy                           0.97       244
    macro avg       0.97      0.97      0.97       244
 weighted avg       0.97      0.97      0.97       244
```

âœ… Average F1 Score: 0.9446

---

## ğŸ“ Lessons Learned

- **Hybrid approach** (deep features + Random Forest) excels in low-data settings
- **Macro F1** is crucial for imbalanced classes
- **Visual inspection** of misclassifications guides augmentation strategies

---

## ğŸ‘¤ About Me

**Sanskar Khandelwal**  
- Kaggle: [sankhuz](https://www.kaggle.com/sankhuz)  
- Team: TheLastTransformer ğŸš€

Feel free to â­ the repo and share feedback!


