{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb822670",
   "metadata": {},
   "source": [
    "# üîç Inference - Soil Detection Challenge\n",
    "\n",
    "This notebook loads the trained soil classifier and runs inference on the test set provided in `test_ids.csv`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ee709",
   "metadata": {},
   "source": [
    "# Imports Explanation\n",
    "We import essential libraries: numpy for array operations, pandas for data handling, sklearn modules for scaling, modeling and evaluation, and json for saving metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7afb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65103cfe",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "We standardize features by fitting StandardScaler on training data and applying the same transformation to test data to ensure consistent input distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73883aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = OneClassSVM(kernel='rbf', gamma='scale', nu=0.1)\n",
    "svm.fit(train_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e48d74",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "We initialize a One-Class SVM with RBF kernel to learn the distribution of soil images and fit it on the scaled training features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_preds = svm.predict(test_features)\n",
    "binary_preds = [1 if p == 1 else 0 for p in svm_preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbd2b5",
   "metadata": {},
   "source": [
    "# Inference on Test Set\n",
    "Using the trained SVM, we predict on test features. Raw outputs (1 for inlier, -1 for outlier) are mapped to binary labels (1 for soil, 0 for non-soil)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e803191",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'image_id': test_ids,\n",
    "    'label': binary_preds\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"‚úÖ Submission file saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a40ce1",
   "metadata": {},
   "source": [
    "# Submission File Creation\n",
    "We create a pandas DataFrame mapping each image ID to its predicted label and save the results as `submission.csv` for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = svm.predict(train_features)\n",
    "binary_train_preds = [1 if p == 1 else 0 for p in train_preds]\n",
    "train_labels = [1] * len(binary_train_preds)\n",
    "recall = recall_score(train_labels, binary_train_preds)\n",
    "false_negatives = sum([1 for p in binary_train_preds if p == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd54e77",
   "metadata": {},
   "source": [
    "# Evaluation on Training Data\n",
    "To gauge model performance on known data, we predict on the training set, calculate recall, and count false negatives (soil classified as non-soil)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62656427",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"task\": \"One-Class Soil Detection\",\n",
    "    \"approach\": \"Anomaly Detection using ResNet18 + One-Class SVM\",\n",
    "    \"model\": {\n",
    "        \"feature_extractor\": \"ResNet18 (ImageNet pretrained)\",\n",
    "        \"anomaly_model\": \"OneClassSVM (RBF kernel)\",\n",
    "        \"feature_dim\": int(train_features.shape[1]),\n",
    "        \"nu\": 0.1,\n",
    "        \"scaler\": \"StandardScaler (mean=0, std=1)\",\n",
    "        \"training_samples\": len(train_labels)\n",
    "    },\n",
    "    \"training_data_used\": \"Only positive class (soil images)\",\n",
    "    \"testing_goal\": \"Identify non-soil images as outliers\",\n",
    "    \"evaluation\": {\n",
    "        \"recall_on_soil_train\": recall,\n",
    "        \"false_negatives_estimate\": false_negatives,\n",
    "        \"recall_percent\": round(recall * 100, 2)\n",
    "    },\n",
    "   \n",
    "    \n",
    "    \"team_info\": {\n",
    "        \"name\": \"Sanskar Khandelwal\",\n",
    "        \"kaggle_username\": \"sankhuz\",\n",
    "        \"team\": \"TheLastTransformer\"\n",
    "    },\n",
    "    \"files\": {\n",
    "        \"train_features\": \"train_features.npy\",\n",
    "        \"test_features\": \"test_features.npy\",\n",
    "        \"test_ids\": \"test_ids.npy\",\n",
    "        \"metrics_file\": \"metrics.json\"\n",
    "    },\n",
    "    \"notes\": \"Model trained only on positive samples. No non-soil training data used.\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b47451",
   "metadata": {},
   "source": [
    "# Metrics Construction\n",
    "We build a structured metrics dictionary capturing task details, model parameters, dataset sizes, and evaluation results for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10530c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Improved metrics.json saved.\")\n",
    "\n",
    "with open(\"metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ metrics.json saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a190b",
   "metadata": {},
   "source": [
    "# Saving Metrics\n",
    "We serialize the metrics dictionary into `metrics.json` to document our experiment configuration and outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb163117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Predict on test set\n",
    "# Output: 1 = inlier (soil), -1 = outlier (non-soil)\n",
    "svm_preds = svm.predict(test_features)\n",
    "binary_preds = [1 if p == 1 else 0 for p in svm_preds]  # Convert to 1/0\n",
    "# 11. Save Submission\n",
    "submission = pd.DataFrame({\n",
    "    'image_id': test_ids,\n",
    "    'label': binary_preds\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\" Submission file saved as 'submission.csv'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
